{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team 17\r\n",
    "\r\n",
    "# 109020039, 109020015, X1110071, X1110072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\r\n",
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "import matplotlib\r\n",
    "import numpy\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"small_df.csv\",delimiter=',')\r\n",
    "df.drop(index=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc = df.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take Subway for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(df['Subway'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I would like to mention menu for Vegetarians.\\r\\n\\r\\nLike in Subway, they can go for Falafel Sandwich which is very good option for them even they can try veg sandwich.\\r\\n\\r\\nAnd also you can try cookies which cost around 50 for 3 pieces.',\n",
       " \"'Great food, but I think service can be better, the speed of serve and order aren’t quick enough.']\",\n",
       " \"'This is the nearest Subway to Section 2 Guangfu Road. This has all the latest Sub way items available in Taiwan. You can dine in/ take out.']\",\n",
       " '\"Pretty solid for Subway. You will have some issues finding parking for a car but on the other hand there\\'s almost never any wait time. The place is also next to a711 which makes it convenient to get the same drink for 10 ntd less.\"]',\n",
       " '\"What\\'s with the attitude?\\\\nI asked for some extra veggies and it\\'s totally fine if you couldn\\'t offer me, but you shouldn\\'t have just pretended that you didn\\'t hear me.\\\\nI said THRICE clearly enough for you to hear.\"]']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1,5):\r\n",
    "    data[i] = data[i][4:]\r\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply first skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Master\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"textattack/roberta-base-SST-2\" # This code snippet loads the textattack/roberta-base-SST-2 model, which is a RoBERTa model fine-tuned for the SST-2 (Stanford Sentiment Treebank) dataset.\r\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Roberta(text):\r\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\r\n",
    "    with torch.no_grad():\r\n",
    "        outputs = model(**inputs)\r\n",
    "        logits = outputs.logits\r\n",
    "    sentiment_class = torch.argmax(logits).item()\r\n",
    "    if sentiment_class == 1:\r\n",
    "        print(f\"The sentiment of the input text is positive.\")\r\n",
    "    else:\r\n",
    "        print(f\"The sentiment of the input text is negative.\")\r\n",
    "    return sentiment_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the input text is positive.\n",
      "The sentiment of the input text is negative.\n",
      "The sentiment of the input text is positive.\n",
      "The sentiment of the input text is positive.\n",
      "The sentiment of the input text is negative.\n",
      "The number of positive comments is 3\n",
      "The number of negative comments is 2\n"
     ]
    }
   ],
   "source": [
    "pos = 0\r\n",
    "neg = 0\r\n",
    "for item in data:\r\n",
    "    if(Roberta(item)==1):\r\n",
    "        pos = pos+1\r\n",
    "    else:\r\n",
    "        neg = neg+1\r\n",
    "\r\n",
    "print(\"The number of positive comments is\",pos)\r\n",
    "print(\"The number of negative comments is\",neg)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concusion of first skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rank of second and fifith comments are 3 and 2, respectively, which is insistant with the above result (both of them are negative)\r\n",
    "\r\n",
    "While all the others have higher rank, they are valued as positive.\r\n",
    "\r\n",
    "Hence we can see that the model predicted correcticely in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply second skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to mention menu for Vegetarians.Like in Subway, they can go for Falafel Sandwich which is very good option for them even they can try veg sandwich.And also you can try cookies which cost around 50 for 3 pieces. Great food, but I think service can be better, the speed of serve and order aren’t quick enough. This is the nearest Subway to Section 2 Guangfu Road. This has all the latest Sub way items available in Taiwan. You can dine in take out. Pretty solid for Subway. You will have some issues finding parking for a car but on the other hand theres almost never any wait time. The place is also next to a711 which makes it convenient to get the same drink for 10 ntd less. Whats with the attitude?nI asked for some extra veggies and its totally fine if you couldnt offer me, but you shouldnt have just pretended that you didnt hear me.nI said THRICE clearly enough for you to hear.\n"
     ]
    }
   ],
   "source": [
    "data2 = \" \".join(data)\r\n",
    "stopword = [\"\\\\\",\"[\",\"]\",\"\\r\",\"\\n\",\"'\",'\"',\"/\"]\r\n",
    "\r\n",
    "data2 = [word for word  in data2 if word not in stopword]\r\n",
    "\r\n",
    "data2 = \"\".join(data2)\r\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\r\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\r\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Great food, but I think service can be better, the speed of serve and order aren’t quick enough. This is the nearest Subway to Section 2 Guangfu Road. You can dine in take out. Pretty solid for Subway. You will have some issues finding parking for a car but on the other hand theres almost never any wait time.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input text and convert it to a PyTorch tensor\r\n",
    "inputs = tokenizer(data2, return_tensors=\"pt\", max_length=1024, truncation=True)\r\n",
    "\r\n",
    "# Perform text summarization using the BART model\r\n",
    "with torch.no_grad():\r\n",
    "    outputs = model.generate(**inputs)\r\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\r\n",
    "\r\n",
    "# Display the result\r\n",
    "print(f\"Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concusion for second skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conbine all the comments of this restaurant into a single string and remove some stopwords. \r\n",
    "\r\n",
    "And the summary provided overall thought of this restaurant."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fed83269f86bf221e676bbe433824654e89693622224fbf48225c086bf7076f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}