{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\r\n",
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "import matplotlib\r\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"small_df.csv\",delimiter=',')\r\n",
    "df.drop(index=[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc = df.to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\r\n",
    "for key in df:\r\n",
    "    data[key] = list(df[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Master\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\r\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"textattack/roberta-base-SST-2\" # This code snippet loads the textattack/roberta-base-SST-2 model, which is a RoBERTa model fine-tuned for the SST-2 (Stanford Sentiment Treebank) dataset.\r\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\r\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pos_Neg(text):\r\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\r\n",
    "    with torch.no_grad():\r\n",
    "        outputs = model(**inputs)\r\n",
    "        logits = outputs.logits\r\n",
    "    sentiment_class = torch.argmax(logits).item()\r\n",
    "    return sentiment_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'This is the nearest Subway to Section 2 Guangfu Road. This has all the latest Sub way items available in Taiwan. You can dine in/ take out.']\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Subway\"][2][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summ = {} #take only positive comments for summary\r\n",
    "stopword = [\"\\\\\",\"[\",\"]\",\"\\r\",\"\\n\",\"'\",'\"',\"/\"]\r\n",
    "for key in data:\r\n",
    "    buffer = []\r\n",
    "    i=0\r\n",
    "    for comm in data[key]:\r\n",
    "        if(i):\r\n",
    "            comm = comm[4:]\r\n",
    "        else:\r\n",
    "            i=1\r\n",
    "        if(Pos_Neg(comm) == 1):\r\n",
    "            comm = [word for word  in comm if word not in stopword]\r\n",
    "            comm = \"\".join(comm)\r\n",
    "            buffer.append(comm)\r\n",
    "            \r\n",
    "    data_summ[key] = \" \".join(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\r\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\r\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Summary(data):\r\n",
    "    # Tokenize the input text and convert it to a PyTorch tensor\r\n",
    "    inputs = tokenizer(data, return_tensors=\"pt\", max_length=1024, truncation=True)\r\n",
    "    # Perform text summarization using the BART model\r\n",
    "    with torch.no_grad():\r\n",
    "        outputs = model.generate(**inputs)\r\n",
    "        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\r\n",
    "    # Display the result\r\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dict = {}\r\n",
    "for key in data_summ:\r\n",
    "        summary_dict[key] = Summary(data_summ[key])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0xa4\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      2\u001b[0m summary \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[43msummary_dict\u001b[49m:\n\u001b[0;32m      4\u001b[0m     val \u001b[38;5;241m=\u001b[39m summary_dict[key]\n\u001b[0;32m      5\u001b[0m     val \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word  \u001b[38;5;129;01min\u001b[39;00m val \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m s]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'summary_dict' is not defined"
     ]
    }
   ],
   "source": [
    "s = [\"\\xa0\",\"0xa4\"]\r\n",
    "summary = {}\r\n",
    "for key in summary_dict:\r\n",
    "    val = summary_dict[key]\r\n",
    "    val = [word for word  in val if word not in s]\r\n",
    "    val = \"\".join(val)\r\n",
    "    summary[key] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\r\n",
    "\r\n",
    "with open('Summaries_of_restaurants.csv', 'w', newline='') as csvfile:\r\n",
    "  # 定義欄位\r\n",
    "  fieldnames = ['Restaurant', 'Summary']\r\n",
    "\r\n",
    "  # 將 dictionary 寫入 CSV 檔\r\n",
    "  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\r\n",
    "\r\n",
    "  # 寫入第一列的欄位名稱\r\n",
    "  writer.writeheader()\r\n",
    "\r\n",
    "  # 寫入資料\r\n",
    "  for key in summary:\r\n",
    "    writer.writerow({'Restaurant' : key, 'Summary':summary[key]})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fed83269f86bf221e676bbe433824654e89693622224fbf48225c086bf7076f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}